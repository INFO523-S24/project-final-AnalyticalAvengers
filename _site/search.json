[
  {
    "objectID": "presentation.html#question-1",
    "href": "presentation.html#question-1",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Question 1:",
    "text": "Question 1:\nWhich age groups are at the highest risk of getting into severe crashes, and how do factors like lighting, weather, road conditions, speed limits, and the number of vehicles involved contribute to the likelihood of certain age groups being in more danger?"
  },
  {
    "objectID": "presentation.html#plots-for-question-1",
    "href": "presentation.html#plots-for-question-1",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Plots for question 1",
    "text": "Plots for question 1\n\nPlot AInsights\n\n\n\n\n\nBar Plot visualizing the Severity of car crashes across different age groups:\n\n\n\n\n\nThe plot visualizes the distribution of crashes across different age groups, categorized by crash severity (No injury, Minor Injury, etc.).\nBy analyzing the height of the bars for each age group and severity level, you can identify which age groups are more likely to be involved in crashes of varying severity.\nthe plot might show that younger or older drivers have a higher number of crashes with minor injuries compared to middle-aged drivers."
  },
  {
    "objectID": "presentation.html#section-1",
    "href": "presentation.html#section-1",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "Plot CInsights\n\n\n\n\n\nHeatmap of Crash Severity by Age Group and Light Conditions:\n\n\n\n\n\nThe heatmap allows for a more nuanced analysis compared to count plots. The color intensity visually represents the proportion of crashes with different severities under varying lighting conditions for each age group.\nYou can identify trends like: Age groups with a higher proportion of severe crashes under dark conditions compared to well-lit conditions. Specific lighting conditions where a particular age group experiences a higher proportion of crashes of a certain severity ."
  },
  {
    "objectID": "presentation.html#section-2",
    "href": "presentation.html#section-2",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "Plot DInsights\n\n\n\n\n\nCrash Severity by Weather Conditions:\n\n\n\n\n\nThe plot shows the number of crashes with different severity levels (No injury, Minor Injury, etc.) under various weather conditions (Clear, Rain, Snow, etc.).\nBy analyzing the height of the bars for each weather condition and severity level, you can identify weather conditions with a higher number of crashes of varying severity."
  },
  {
    "objectID": "presentation.html#section-3",
    "href": "presentation.html#section-3",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "Plot DInsights\n\n\n\n\n\nCrash Severity by Weather Conditions:\n\n\n\n\n\nThe plot shows the number of crashes with different severity levels (No injury, Minor Injury, etc.) under various weather conditions (Clear, Rain, Snow, etc.).\nBy analyzing the height of the bars for each weather condition and severity level, you can identify weather conditions with a higher number of crashes of varying severity."
  },
  {
    "objectID": "presentation.html#question-2",
    "href": "presentation.html#question-2",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Question 2:",
    "text": "Question 2:\nIs it possible to develop a model that can accurately classify the severity of crashes based on our findings from the previous question about factors that contribute to said level of danger?"
  },
  {
    "objectID": "presentation.html#plots-for-question-2",
    "href": "presentation.html#plots-for-question-2",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Plots for question 2",
    "text": "Plots for question 2"
  },
  {
    "objectID": "presentation.html#model-development-and-evaluation",
    "href": "presentation.html#model-development-and-evaluation",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Model Development and Evaluation",
    "text": "Model Development and Evaluation\nBuilding on the insights from Question 1, our aim in Question 2 is to develop and evaluate predictive models that can accurately classify the severity of crashes. This section describes our approach to modeling, including data preparation, feature selection, model training, and evaluation."
  },
  {
    "objectID": "presentation.html#data-preparation-and-feature-selection",
    "href": "presentation.html#data-preparation-and-feature-selection",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Data Preparation and Feature Selection",
    "text": "Data Preparation and Feature Selection\nWe filtered the data to exclude rows with unknown severity and then created a binary target variable to distinguish between ‘no injury’ and ‘injury/fatality’ crashes. We focused on features identified as potentially influential, such as Speed Limit, Light Conditions, and Weather Conditions."
  },
  {
    "objectID": "presentation.html#model-training",
    "href": "presentation.html#model-training",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Model Training",
    "text": "Model Training\nWe trained four different machine learning models: Logistic Regression, Decision Tree, Random Forest, and K-Nearest Neighbors. Each model was evaluated using a split of 80% training data and 20% testing data."
  },
  {
    "objectID": "presentation.html#model-evaluation",
    "href": "presentation.html#model-evaluation",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Model Evaluation",
    "text": "Model Evaluation\nWe assessed the models based on accuracy, precision, recall, and F1-score. Additionally, we computed the ROC curves and AUC to evaluate the models’ performance comprehensively."
  },
  {
    "objectID": "presentation.html#visualizations-for-question-2",
    "href": "presentation.html#visualizations-for-question-2",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Visualizations for Question 2",
    "text": "Visualizations for Question 2\n\nCorrelation MatrixInsights\n\n\n\n\n\nCorrelation matrix and pair plot showing the relationship between numerical features and the target variable.\n\n\n\n\n\nThe correlation matrix helps identify the lack of strong linear relationships, suggesting that non-linear modeling techniques may be more effective."
  },
  {
    "objectID": "presentation.html#question-2-is-it-possible-to-develop-a-model-that-can-accurately-classify-the-severity-of-crashes-based-on-our-findings-from-the-previous-question-about-factors-that-contribute-to-said-level-of-danger",
    "href": "presentation.html#question-2-is-it-possible-to-develop-a-model-that-can-accurately-classify-the-severity-of-crashes-based-on-our-findings-from-the-previous-question-about-factors-that-contribute-to-said-level-of-danger",
    "title": "Project title",
    "section": "Question 2: Is it possible to develop a model that can accurately classify the severity of crashes based on our findings from the previous question about factors that contribute to said level of danger?",
    "text": "Question 2: Is it possible to develop a model that can accurately classify the severity of crashes based on our findings from the previous question about factors that contribute to said level of danger?"
  },
  {
    "objectID": "presentation.html#discussion-and-conclusions",
    "href": "presentation.html#discussion-and-conclusions",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Discussion and Conclusions",
    "text": "Discussion and Conclusions\nThe models developed in this study provide a foundation for predicting crash severity with a reasonable degree of accuracy. However, the imbalance in the dataset poses a challenge, as models tend to predict the majority class more frequently."
  },
  {
    "objectID": "presentation.html#section-4",
    "href": "presentation.html#section-4",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "::: panel-tabset #### ROC Curve \nInsights\n\nThe ROC curve illustrates the trade-off between sensitivity and specificity. Random Forest shows the highest AUC, indicating the best performance among the tested models in distinguishing between the crash severities."
  },
  {
    "objectID": "presentation.html#section-5",
    "href": "presentation.html#section-5",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "::: panel-tabset #### ROC Curve \nInsights\n\nThe ROC curve illustrates the trade-off between sensitivity and specificity. Random Forest shows the highest AUC, indicating the best performance among the tested models in distinguishing between the crash severities."
  },
  {
    "objectID": "presentation.html#recommendations-for-future-work",
    "href": "presentation.html#recommendations-for-future-work",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Recommendations for Future Work",
    "text": "Recommendations for Future Work\n\nInvestigate more sophisticated balancing techniques like SMOTE or targeted sampling methods.\nExplore more complex models or ensemble methods that may capture interactions between features more effectively.\nConsider integrating more contextual data that could impact crash severity, such as time of day or specific event data like traffic volume."
  },
  {
    "objectID": "presentation.html#section-6",
    "href": "presentation.html#section-6",
    "title": "Project title",
    "section": "",
    "text": "Confusion Matrices for ModelsInsights\n\n\n\n\n\nConfusion matrices for Logistic Regression, KNN, Decision Tree, and Random Forest models.\n\n\n\n\n\nThe confusion matrices reveal the performance of each model in predicting the correct classes. Notably, Random Forest balanced the recall and precision better than other models, effectively managing the class imbalance."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANALYTICAL AVENGERS",
    "section": "",
    "text": "This study investigates the relationship between age demographics and severe crashes, with a focus on developing a predictive model to enhance road safety in Massachusetts. Using a crash dataset from January 2024, we explore how age correlates with the severity of crashes and examine environmental factors like lighting, weather, road conditions, speed limits, and the number of vehicles involved. Our analysis reveals crucial patterns, indicating which age groups, both drivers and vulnerable users, are at greater risk of severe crashes. Additionally, we identify environmental conditions that contribute to the likelihood and severity of crashes, providing insights for targeted safety measures. To classify crash severity, we experimented with various machine learning (ML) techniques, including logistic regression, decision trees, random forests, and K Nearest Neighbors (KNN). Our models achieved a prediction accuracy of around 78% in all cases, indicating a strong ability to classify crash severity based on the selected features. However, the absence of road volume or vehicle miles traveled data poses a limitation in contextualizing the frequency of crashes. The outcomes of our research offer valuable tools for policymakers and practitioners, allowing for more proactive safety measures and resource allocation. By accurately predicting crash risks based on age demographics and environmental conditions, authorities can implement preemptive interventions to reduce severe accidents. Ultimately, this study contributes to a data-driven approach to road safety, with the potential to make tangible improvements in public safety and traffic management."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "ANALYTICAL AVENGERS",
    "section": "",
    "text": "This study investigates the relationship between age demographics and severe crashes, with a focus on developing a predictive model to enhance road safety in Massachusetts. Using a crash dataset from January 2024, we explore how age correlates with the severity of crashes and examine environmental factors like lighting, weather, road conditions, speed limits, and the number of vehicles involved. Our analysis reveals crucial patterns, indicating which age groups, both drivers and vulnerable users, are at greater risk of severe crashes. Additionally, we identify environmental conditions that contribute to the likelihood and severity of crashes, providing insights for targeted safety measures. To classify crash severity, we experimented with various machine learning (ML) techniques, including logistic regression, decision trees, random forests, and K Nearest Neighbors (KNN). Our models achieved a prediction accuracy of around 78% in all cases, indicating a strong ability to classify crash severity based on the selected features. However, the absence of road volume or vehicle miles traveled data poses a limitation in contextualizing the frequency of crashes. The outcomes of our research offer valuable tools for policymakers and practitioners, allowing for more proactive safety measures and resource allocation. By accurately predicting crash risks based on age demographics and environmental conditions, authorities can implement preemptive interventions to reduce severe accidents. Ultimately, this study contributes to a data-driven approach to road safety, with the potential to make tangible improvements in public safety and traffic management."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "ANALYTICAL AVENGERS",
    "section": "Introduction",
    "text": "Introduction\nUnderstanding the factors contributing to severe car crashes is crucial for improving road safety and reducing traffic-related injuries and fatalities. This project aims to develop a predictive model that correlates age demographics with severe crashes in Massachusetts. The ultimate goal is to identify key risk factors and provide data-driven insights for implementing effective safety measures.\nOur team is analyzing a comprehensive dataset of car crashes from January 2024, collected from the Massachusetts Registry of Motor Vehicles. This dataset comprises 72 dimensions, encompassing a range of variables, including crash characteristics, driver demographics, environmental conditions, and vehicle information. By examining these variables, we seek to uncover patterns that link age with severe crashes, offering valuable insights into potential high-risk groups and circumstances.\nOur analysis focuses on two main research questions: identifying the age groups most at risk for severe crashes and exploring the role of environmental factors such as lighting, weather, road conditions, and speed limits. Additionally, we aim to develop a predictive model capable of classifying crash severity based on these variables. To achieve this, we used multiple binary classification models, which are known for their simplicity and effectiveness in classification tasks.\nThe methodology for our analysis involved several key steps. First, we pre-processed the dataset to handle missing data, standardize categorical variables, and scale numerical features. Next, we conducted exploratory data analysis to identify significant correlations and patterns. To predict crash severity, we trained a KNN model using a subset of the data and evaluated its performance on a separate test set. The model’s accuracy, precision, recall, and F1-score were measured to determine its effectiveness. The high accuracy achieved in the model’s predictions indicates its potential for real-world application in road safety.\nThis report details our approach to analyzing the Massachusetts crash dataset, including the steps taken to process the data, build the predictive model, and evaluate its performance. We discuss our findings and provide insights into which age groups are most at risk, along with the environmental factors that contribute to severe crashes. Through this work, we aim to contribute to road safety practices and provide useful information for policymakers, traffic safety professionals, and other stakeholders interested in reducing traffic-related incidents and enhancing public safety."
  },
  {
    "objectID": "index.html#questions",
    "href": "index.html#questions",
    "title": "ANALYTICAL AVENGERS",
    "section": "Questions",
    "text": "Questions\n\nWhich age groups are at the highest risk of getting into severe crashes, and how do factors like lighting, weather, road conditions, speed limits, and the number of vehicles involved contribute to the likelihood of certain age groups being in more danger?\nIs it possible to develop a model that can accurately classify the severity of crashes based on our findings from the previous question about factors that contribute to said level of danger?"
  },
  {
    "objectID": "index.html#analysis-plan",
    "href": "index.html#analysis-plan",
    "title": "ANALYTICAL AVENGERS",
    "section": "Analysis Plan",
    "text": "Analysis Plan\nAs with any data analysis, the first step involves loading the necessary packages and importing the dataset. This ensures that all required tools and resources are available for the subsequent analysis. The output below displays the various data types in our dataset, providing a comprehensive overview of the features at our disposal, thanks to the Massachusetts Department of Transportation (MassDOT).\nTo get a better understanding of our data, we examine the count of each data type to identify the composition of our dataset, including numerical, categorical, and text-based features. Additionally, we present the first few rows of the dataset (the “head”) to give an initial overview of its structure and content. This initial exploration helps set the stage for further data processing, cleaning, and analysis, ensuring that we start with a clear understanding of the dataset’s characteristics and layout.\n\n\nCount of each data type in the DataFrame:\nobject     59\nfloat64    13\ndtype: int64\n\n\n\n\n\n\n\n\n\n\nCrash Number\nCity Town Name\nCrash Date\nCrash Severity\nCrash Status\nCrash Time\nCrash Year\nMax Injury Severity Reported\nNumber of Vehicles\nPolice Agency Type\n...\nX\nY\nLatitude\nLongitude\nVehicle Unit Number\nVehicle Make\nVehicle Model\nPerson Number\nAge\nSex\n\n\n\n\n0\n5342297\nLOWELL\n01/01/2024\nNon-fatal injury\nOpen\n3:26 AM\n2024.0\nPossible Injury (C)\n1.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n1.0\nHOND\nHR-V\n1.0\n32.0\nF - Female\n\n\n1\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n1.0\nNISS\nALTIMA\n1.0\n60.0\nM - Male\n\n\n2\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n2.0\nHOND\nACCORD\n2.0\nNaN\nNaN\n\n\n3\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n2.0\nHOND\nACCORD\n3.0\n31.0\nM - Male\n\n\n4\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n2.0\nHOND\nACCORD\n4.0\nNaN\nM - Male\n\n\n\n\n5 rows × 72 columns\n\n\n\n\nQuestion 1\nTo address Question 1, the analysis begins with a detailed examination of the 13 float variables identified in the previous section. The first step involves using the ‘.describe()’ method to generate initial summary statistics for these variables. This provides a quick overview of the data distribution, central tendencies, and dispersion, which is essential for understanding the basic characteristics of the numerical features.\nThe summary statistics include key metrics such as mean, median, standard deviation, minimum and maximum values, and quartiles. By analyzing these statistics, we can identify potential outliers, skewness, and other characteristics that may influence subsequent analysis. This foundational step allows us to assess the general trends and variations within the float variables, offering insights into how they may relate to the target variable and other categorical features in the dataset.\n\n\n\n\n\n\n\n\n\nCrash Year\nNumber of Vehicles\nMassDOT District\nTotal Fatalities\nTotal Non-Fatal Injuries\nSpeed Limit\nX\nY\nLatitude\nLongitude\nVehicle Unit Number\nPerson Number\nAge\n\n\n\n\ncount\n25547.0\n25547.000000\n25547.000000\n25547.000000\n25547.000000\n23389.000000\n21002.000000\n21002.000000\n20823.000000\n20823.000000\n25220.000000\n25547.000000\n23002.000000\n\n\nmean\n2024.0\n1.976749\n4.019063\n0.003562\n0.318824\n34.394502\n205930.128516\n887470.383156\n42.234940\n-71.431249\n1.489968\n1.918699\n38.952265\n\n\nstd\n0.0\n0.702530\n1.325421\n0.068730\n0.728140\n12.979679\n49539.383540\n31782.135543\n0.287058\n0.600959\n0.637851\n1.568750\n18.503512\n\n\nmin\n2024.0\n1.000000\n1.000000\n0.000000\n0.000000\n1.000000\n44708.708525\n779050.104521\n41.251611\n-73.386241\n1.000000\n1.000000\n0.000000\n\n\n25%\n2024.0\n2.000000\n3.000000\n0.000000\n0.000000\n25.000000\n179154.370652\n870946.937400\n42.086592\n-71.756001\n1.000000\n1.000000\n24.000000\n\n\n50%\n2024.0\n2.000000\n4.000000\n0.000000\n0.000000\n30.000000\n224092.943601\n889548.926635\n42.254041\n-71.209095\n1.000000\n2.000000\n36.000000\n\n\n75%\n2024.0\n2.000000\n5.000000\n0.000000\n0.000000\n40.000000\n237299.607076\n908937.437400\n42.428108\n-71.049485\n2.000000\n2.000000\n53.000000\n\n\nmax\n2024.0\n9.000000\n6.000000\n3.000000\n8.000000\n65.000000\n327948.082270\n958417.191000\n42.874973\n-69.962834\n9.000000\n42.000000\n99.000000\n\n\n\n\n\n\n\nAs part of the analysis plan for Question 1, the next step involves identifying missing values and duplicate rows in the dataset. Given that the question focuses on age groups at the highest risk of severe crashes and the factors that contribute to crash severity, it’s crucial to ensure the data’s completeness and consistency.\nTo examine the missing data, we check for missing values in the following columns, which are directly related to the question: ‘Age’, ‘Light Conditions’, ‘Weather Conditions’, and ‘Road Surface Condition’. Any missing values in these columns could affect the analysis, as they are critical in determining the conditions under which severe crashes occur and the age groups most likely to be involved.\n\n\nAge                       2548\nLight Conditions             3\nWeather Conditions           3\nRoad Surface Condition       3\ndtype: int64\n\n\nIn dealing with missing values, we apply different imputation strategies depending on the column type and context. For the ‘Light Conditions’, ‘Weather Conditions’, and ‘Road Surface Condition’ columns, which are categorical, mode imputation is used to fill in missing values. Mode imputation replaces missing entries with the most frequently occurring value, ensuring that the most common data pattern is retained without introducing significant bias.\nFor the ‘Age’ column, which is numerical, median imputation is employed. The median provides a robust measure of central tendency, less susceptible to outliers compared to the mean. This approach is particularly useful when dealing with skewed data or avoiding distortions from extreme values.\nIn question 2, which involves building machine learning models, we opt to filter out rows with missing values to avoid biasing the model. However, for this current analysis, mode and median imputation are applied to maintain the dataset’s size and continuity. Imputation is chosen here to preserve the context and integrity of the data, allowing for a more comprehensive analysis of crash-related factors.\nFollowing imputation, the ‘Age’ column is binned into age groups based on the age ranges provided by MassDOT. This transformation is crucial for analyzing the distribution of crash severity across different age groups. Our first visualization is a bar plot displaying the relationship between age group and crash severity, using ‘Crash Severity’ as the data source. This plot provides a clear visual representation of how crash severity is distributed across age groups, helping to identify patterns or trends that could inform further analysis and safety recommendations.\n\n\nCode\n# Replace 'Property damage only (none injured)' with 'No injury'\ncrash_data['Crash Severity'].replace('Property damage only (none injured)', 'No injury', inplace=True)\n\n# Plot with rotated x-axis labels\nplt.figure(figsize=(8, 6))  # Set plot size\nsns.countplot(x='Age Group', hue='Crash Severity', data=crash_data, palette='coolwarm')  # Plot with seaborn\nplt.title('Crash Severity Distribution by Driver Age Group')  # Set title\nplt.xlabel('Age Group Driver')  # Set x-axis label\nplt.ylabel('Number of Crashes')  # Set y-axis label\nplt.xticks(rotation=45)  # Rotate x-axis labels\nplt.legend(title='Crash Severity')  # Set legend title\nplt.show()  # Display the plot\n\n\n\n\n\n\n\n\n\nThe bar plot displaying the distribution of crashes by age group shows a roughly normal distribution, suggesting that crash frequency generally increases with age and then tapers off at older ages. This pattern is consistent across the overall number of crashes and when broken down by individual crash severities.\nHowever, one significant observation is the clear imbalance in the data, with a disproportionately high number of crashes classified as “no-injury” compared to other severity levels. This imbalance can impact subsequent analyses, as the majority of crashes fall into this less severe category, potentially overshadowing more critical, severe crash cases. This insight underscores the importance of addressing data imbalance when building predictive models or drawing conclusions from the data.\n\n\nCode\n# Replace longer labels with shorter ones\ncrash_data['Light Conditions'].replace('Dark - unknown roadway lighting', 'Dark - unknown lighting', inplace=True)\ncrash_data['Light Conditions'].replace('Dark - roadway not lighted', 'Dark - no lighting', inplace=True)\n\nplt.figure(figsize=(8, 6))\nsns.countplot(x='Light Conditions', hue='Crash Severity', data=crash_data, palette='coolwarm')\nplt.title('Crash Severity by Light Conditions')\nplt.xlabel('Light Conditions')\nplt.ylabel('Number of Crashes')\nplt.legend(title='Crash Severity')\nplt.xticks(rotation=75)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe analysis of crash occurrences by light conditions reveals that daylight is the most common setting for crashes. This is unsurprising, as most drivers are on the road during daylight hours, commuting to work, school, or running errands. The higher traffic volumes during these times naturally lead to more accidents.\nFollowing daylight, the next most common light condition for crashes is “dark-lighted roadway.” This observation is consistent with the typical layout of urban and suburban areas where streetlights are more prevalent, providing better visibility at night. In contrast, rural areas with fewer lighted roadways tend to have less traffic, contributing to fewer overall crashes.\nOnce again, the data shows a noticeable imbalance in crash severity. The majority of crashes fall into the “no-injury” category, indicating that while accidents are more frequent during daylight and on lighted roadways, they are generally less severe. This recurring pattern of severity imbalance suggests that even as crash frequency fluctuates with light conditions, the majority remain relatively minor in nature.\n\n\nCode\n# Create a pivot table to summarize data\npivot_table = pd.pivot_table(crash_data, values='Crash Severity', index='Age Group', \n                             columns='Light Conditions', aggfunc='count')\n\n# Normalize the pivot table by row (to show proportions across light conditions)\nnorm_pivot = pivot_table.div(pivot_table.sum(axis=1), axis=0)\n\n# Set up the plot\nplt.figure(figsize=(10, 6))\nheatmap = sns.heatmap(norm_pivot, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', cbar=True)\nplt.xticks(rotation=75)  # Rotate x-axis tick labels\nplt.yticks(rotation=45)  # Rotate y-axis tick labels \nplt.title('Heatmap of Crash Severity by Age Group and Light Conditions')\nplt.xlabel('Light Conditions')  # Label for x-axis\nplt.ylabel('Age Group')  # Label for y-axis\ncbar = heatmap.collections[0].colorbar  # Get the colorbar\ncbar.set_label('Proportion of Crash Severity')  # Indicate proportion of crash types within a group\nplt.show()  # Display the heatmap\n\n\n\n\n\n\n\n\n\nExamining the heatmap of crash severity by age group and light conditions, viewed as a proportion rather than a total count, reveals some intriguing insights. This approach allows us to better understand the relative distribution of crash severities within each category, offering a nuanced perspective on the factors contributing to different types of crashes.\nThe heatmap indicates that the most common age groups and lighting conditions tend to have the highest proportion of no-injury crashes. This observation suggests that higher vehicle volumes, often associated with daytime driving, result in more crashes overall, but these tend to be less severe. A plausible explanation is that during daytime, increased traffic volumes lead to more minor collisions due to congestion and low-speed accidents, which are generally safer.\nAdditionally, the data shows that older people are significantly more likely to be involved in crashes during daylight hours, with a higher proportion of no-injury crashes. This trend aligns with typical driving patterns, where older drivers are less likely to drive at night. This finding may also reflect safer driving behavior among older drivers, who tend to avoid risky conditions such as nighttime driving.\n\n\nCode\n# Mapping from original weather conditions to simplified categories\nweather_mapping = {\n    # Clear weather\n    \"Clear\": \"Clear\",\n    \"Clear/Clear\": \"Clear\",\n    \"Clear/Cloudy\": \"Clear\",\n    \"Clear/Other\": \"Clear\",\n    \"Clear/Unknown\": \"Clear\",\n    \"Clear/Snow\": \"Clear\",\n    \"Clear/Rain\": \"Clear\",\n    \"Clear/Blowing sand, snow\": \"Clear\",\n\n    # Cloudy weather\n    \"Cloudy\": \"Cloudy\",\n    \"Cloudy/Cloudy\": \"Cloudy\",\n    \"Cloudy/Clear\": \"Cloudy\",\n    \"Cloudy/Unknown\": \"Cloudy\",\n    \"Cloudy/Other\": \"Cloudy\",\n    \"Cloudy/Blowing sand, snow\": \"Cloudy\",\n    \"Cloudy/Fog, smog, smoke\": \"Cloudy\",\n    \n    # Rain\n    \"Rain\": \"Rain\",\n    \"Rain/Rain\": \"Rain\",\n    \"Rain/Cloudy\": \"Rain\",\n    \"Rain/Sleet, hail (freezing rain or drizzle)\": \"Rain\",\n    \"Rain/Fog, smog, smoke\": \"Rain\",\n    \"Rain/Severe crosswinds\": \"Rain\",\n    \"Rain/Other\": \"Rain\",\n    \"Rain/Unknown\": \"Rain\",\n    \n    # Snow\n    \"Snow\": \"Snow\",\n    \"Snow/Snow\": \"Snow\",\n    \"Snow/Cloudy\": \"Snow\",\n    \"Snow/Clear\": \"Snow\",\n    \"Snow/Rain\": \"Snow\",\n    \"Snow/Other\": \"Snow\",\n    \"Snow/Blowing sand, snow\": \"Snow\",\n    \"Snow/Sleet, hail (freezing rain or drizzle)\": \"Snow\",\n    \n    # Sleet, hail\n    \"Sleet, hail (freezing rain or drizzle)\": \"Sleet/Hail\",\n    \"Sleet, hail (freezing rain or drizzle)/Snow\": \"Sleet/Hail\",\n    \"Sleet, hail (freezing rain or drizzle)/Cloudy\": \"Sleet/Hail\",\n    \"Sleet, hail (freezing rain or drizzle)/Severe crosswinds\": \"Sleet/Hail\",\n    \"Sleet, hail (freezing rain or drizzle)/Blowing sand, snow\": \"Sleet/Hail\",\n    \"Sleet, hail (freezing rain or drizzle)/Fog, smog, smoke\": \"Sleet/Hail\",\n    \n    # Severe crosswinds and windy conditions\n    \"Severe crosswinds\": \"Windy\",\n    \"Blowing sand, snow\": \"Windy\",\n    \n    # Fog, smog, smoke\n    \"Fog, smog, smoke\": \"Fog\",\n    \"Fog, smog, smoke/Cloudy\": \"Fog\",\n    \"Fog, smog, smoke/Rain\": \"Fog\",\n    \n    # Other and Unknown\n    \"Unknown\": \"Unknown\",\n    \"Unknown/Unknown\": \"Unknown\",\n    \"Not Reported\": \"Unknown\",\n    \"Other\": \"Other\",\n    \"Reported but invalid\": \"Other\",\n    \"Unknown/Clear\": \"Unknown\",\n    \"Unknown/Other\": \"Unknown\",\n}\n\n# Apply the mapping to simplify the \"Weather Conditions\"\ncrash_data[\"Weather Conditions\"] = crash_data[\"Weather Conditions\"].map(weather_mapping).fillna(\"Other\")\n\nplt.figure(figsize=(8, 6))\nsns.countplot(x='Weather Conditions', hue='Crash Severity', data=crash_data, palette='coolwarm')\nplt.title('Crash Severity by Weather Conditions')\nplt.xlabel('Weather Conditions')\nplt.ylabel('Number of Crashes')\nplt.legend(title='Crash Severity')\nplt.xticks(rotation=45) \nplt.show()\n\n\n\n\n\n\n\n\n\nAfter filtering and simplifying the weather conditions to six main categories, we can analyze their impact on crash occurrences and severity. As expected, clear weather conditions are associated with the highest number of crashes, and, unsurprisingly, “no injury” is the most common outcome. This pattern aligns with general expectations, as most driving occurs during clear weather, with higher traffic volumes leading to more minor accidents.\nInterestingly, the data reveals that snowy conditions are associated with more crashes than cloudy weather, despite cloudy weather likely being more common. This observation suggests that snowy conditions, which often reduce visibility and traction, could increase the likelihood of accidents, even if the overall frequency of such weather is lower. It highlights the unique challenges posed by adverse weather and the potential for more severe accidents in these conditions.\nOne limitation of this analysis is that it does not account for driving rates during different weather conditions. Without additional data, it’s challenging to establish crash rates relative to the frequency of specific weather types. If more comprehensive data were available, it would be possible to calculate crash rates per mile driven or per hour of exposure to provide a more accurate representation of the risks associated with each weather condition.\n\n\nCode\n# summarizing data using a pivot table\npivot_table = pd.pivot_table(crash_data, values='Crash Severity', index='Age Group', columns='Weather Conditions', aggfunc='count')\n\n# Normalize pivot table\nnorm_pivot = pivot_table.div(pivot_table.sum(axis=1), axis=0)\n\nplt.figure(figsize=(10, 6))\nheatmap = sns.heatmap(norm_pivot, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', cbar=True)\nplt.xticks(rotation=45)  # Rotate x-axis tick labels\nplt.yticks(rotation=45)  # Rotate y-axis tick labels\nplt.title('Heatmap of Weather Conditions by Age Group')\nplt.xlabel('Weather Conditions')\nplt.ylabel('Age Group')\ncbar = heatmap.collections[0].colorbar  # Get the colorbar\ncbar.set_label('Proportion of Crash Severity')  # Indicate proportion of crash types within a group\nplt.show()\n\n\n\n\n\n\n\n\n\nThe heatmap depicting the relationship between age groups and weather conditions provides insights into the frequency and severity of crashes under varying weather circumstances. Notably, the majority of non-fatal crashes occur in clear weather conditions. This observation aligns with the previous finding that clear conditions are associated with the highest overall crash counts.\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.countplot(x='Road Surface Condition', hue='Crash Severity', data=crash_data, palette='coolwarm')\nplt.title('Crash Severity by Road Surface Condition')\nplt.xlabel('Road Surface Condition')\nplt.ylabel('Number of Crashes')\nplt.legend(title='Crash Severity')\nplt.xticks(rotation=75) \nplt.show()\n\n\n\n\n\n\n\n\n\nAn analysis of road surface conditions indicates that dry roads have the highest count of overall crashes. This is likely due to the prevalence of dry roads during typical driving conditions and higher traffic volumes. However, road surfaces like wet and snowy also account for a significant number of crashes, highlighting the importance of traction in crash prevention.\n\n\nCode\n# summarizing data using a pivot table\npivot_table = pd.pivot_table(crash_data, values='Crash Severity', index='Age Group', columns='Road Surface Condition', aggfunc='count')\n\n# Normalize pivot table\nnorm_pivot = pivot_table.div(pivot_table.sum(axis=1), axis=0)\n\nheatmap = sns.heatmap(norm_pivot, annot=True, fmt=\".2f\", linewidths=.5, cmap='coolwarm', cbar=True)\nplt.xticks(rotation=75)  # Rotate x-axis tick labels\nplt.yticks(rotation=45)  # Rotate y-axis tick labels\nplt.title('Heatmap of Road surfaces and Age Groups')\nplt.xlabel('Road Surface Condition')\nplt.ylabel('Age Group')\ncbar = heatmap.collections[0].colorbar  # Get the colorbar\ncbar.set_label('Proportion of Crash Severity')  # Indicate proportion of crash types within a group\nplt.show()\n\n\n\n\n\n\n\n\n\nThe heatmap displaying road surface conditions and age groups offers valuable insights into the safety implications of various road surfaces. A notable observation is that unknown and unreported surface conditions are associated with a significant proportion of severe crashes. This might indicate challenges in data collection and reporting by various agencies, suggesting that incomplete data could obscure important safety risks.\nDespite having fewer overall crashes, icy, snowy, and wet roads exhibit higher rates of severe crashes. This finding underscores the danger posed by reduced traction and adverse weather conditions. The correlation between these road surface conditions and crash severity supports the need for additional safety measures, such as improved road maintenance, better reporting practices, and driver education on navigating challenging road conditions.\nOur analysis has provided a clear understanding of the variables most closely associated with crash severity, shedding light on the factors that significantly impact crash outcomes. This knowledge serves as a solid foundation for the modeling process detailed in Question 2, where we hope to build predictive models that leverage these insights. The findings also highlight the pronounced imbalance between no-injury crashes and highly severe crashes, emphasizing the need for public agencies and Departments of Transportation (DOTs) to focus on safety measures for reducing severe incidents. By addressing these disparities and targeting the key variables related to crash severity, we can contribute to improved road safety and more effective traffic management strategies.\n\n\nQuestion 2:\nThe initial analysis from question 1 yielded interesting insights into the relationship between age and crash severity, along with environmental factors like lighting, weather, and road conditions. These findings help identify which age groups are most at risk and the circumstances that contribute to severe crashes. Given these insights, we now move to question 2, where the goal is to create a predictive model to classify crash severity.\nTo start, we need to preprocess the crash data by filtering out rows where the severity is unknown. Next, we create a binary variable to distinguish crashes with “no injury” (property damage only) from those involving injuries or fatalities. This step is crucial due to the heavy imbalance of fatal crashes, which are relatively rare. This binary classification allows for a more straightforward modeling approach, focusing on predicting the likelihood of crashes resulting in injury or fatality. Below, we create a table to display the count of no-injury crashes and injury/fatality crashes to understand the distribution of our target variable.\n\n\nCode\n# Filter rows where the severity is unknow\ncrash_data = crash_data[crash_data['Crash Severity'] != \"Unknown\"]\n\n# Add a new column named 'feature_variable'\ncrash_data['feature_variable'] = [0 if x == 'No injury' else 1 for x in crash_data['Crash Severity']]\n\n# Drop the 'Crash Severity' column\ncrash_data = crash_data.drop('Crash Severity', axis=1)\n\n# Create a count table for the new feature variable\nseverity_counts = crash_data['feature_variable'].value_counts().rename({0: 'No Injury', 1: 'Injury/Fatality'})\n\n# Display the count table\nprint(severity_counts)\n\n\nNo Injury          18996\nInjury/Fatality     5617\nName: feature_variable, dtype: int64\n\n\nWith the target variable established, it is important to explore its relationships with a specific set of feature variables. These variables were chosen based on preliminary analysis and fundamental concepts in traffic engineering, recognizing that certain factors are closely associated with crash severity.\n\nSpeed Limit: Known to be correlated with crash severity.\nLight Conditions: Affects visibility and safety.\nWeather Conditions: Influences road conditions and crash likelihood.\nRoad Surface Condition: Determines traction and safety.\nRoadway Junction Type: Indicates types of intersections and their risks.\nTraffic Control Device Type: Affects traffic flow and safety.\nManner of Collision: Describes the nature of crash events.\nAge: A demographic factor.\nSex: Another demographic factor.\n\nThe following plots include a correlation matrix and a pair plot. The correlation matrix shows that the numeric variables have little to no correlation with each other, indicating independence between them. The pair plot provides a more detailed visualization of the relationships among the numeric features, helping to identify potential patterns or trends not immediately apparent from the raw data.\n\n\nCode\n# Select certain feature variables based on analysis in Q1 and understanding of traffic engineering\ncolumns_to_keep = [\n    'feature_variable',\n    'Light Conditions',\n    'Manner of Collision',\n    'Road Surface Condition',\n    'Roadway Junction Type',\n    'Traffic Control Device Type',\n    'Weather Conditions',\n    'Speed Limit',\n    'Age',\n    'Sex'\n]\n\n# Create the subset from the crash_data DataFrame\nmodel_crash_data = crash_data[columns_to_keep]\n\n\n# Select only numerical columns to create a subset\nnumerical_crash_data = model_crash_data.select_dtypes(include=['int64', 'float64'])\n\n# Now create the correlation matrix with the subset\ncorrelation_matrix = numerical_crash_data.corr()\n\n# Create a heatmap for the correlation matrix\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title(\"Correlation Matrix Heatmap\")\nplt.show()\n\n# Create a pairplot for the numerical subset\nsns.pairplot(numerical_crash_data)\n# plt.title(\"Pairplot for Numerical Columns\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFollowing this, the report includes bar plots for each of the categorical columns and their relationships with the feature variables. These plots serve to highlight the distribution of the categorical data, offering a clearer understanding of how these features relate to the target variable. This analysis aims to uncover meaningful patterns that can guide further investigations and inform safety measures in traffic engineering.\n\n\nCode\n# Perform minor feature engineering for variables with excessive options\n\n# Create a mapping for the \"Sex\" column\nsex_mapping = {\n    \"F - Female\": \"F\",\n    \"M - Male\": \"M\",\n    \"U - Unknown\": \"U\",\n    \"X - Non-Binary\": \"X\"\n}\n\n# Apply the mapping to the \"Sex\" column\nmodel_crash_data[\"Sex\"] = model_crash_data[\"Sex\"].map(sex_mapping)\n\n# Define the age bins and labels\nage_bins = [0, 16, 17, 20, 24, 34, 44, 54, 64, 74, 84, 200]\nage_labels = [\"&lt;16\", \"16-17\", \"18-20\", \"21-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75-84\", \"&gt;84\"]\n\n# Apply binning to the \"Age\" column\nmodel_crash_data[\"Age\"] = pd.cut(model_crash_data[\"Age\"], bins=age_bins, labels=age_labels, right=False)\n\n# Stacked bar plot for Sex and feature_variable\nsns.countplot(x='Sex', hue='feature_variable', data=model_crash_data)\nplt.title(\"Stacked Bar Plot for Sex and feature_variable\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Stacked bar plot for Traffic Control Device Type and feature_variable\nsns.countplot(x='Traffic Control Device Type', hue='feature_variable', data=model_crash_data)\nplt.title(\"Stacked Bar Plot for Traffic Control Device Type and feature_variable\")\nplt.xticks(rotation=90)\nplt.show()\n\n# Stacked bar plot for Weather Conditions and feature_variable\nsns.countplot(x='Weather Conditions', hue='feature_variable', data=model_crash_data)\nplt.title(\"Stacked Bar Plot for Weather Conditions and feature_variable\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Box plot for Age Group and feature_variable\nsns.countplot(x='Age', hue='feature_variable', data=model_crash_data)\nplt.title(\"Box Plot for Age Group and feature_variable\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Crosstab for Roadway Junction Type and feature_variable\nsns.countplot(x='Roadway Junction Type', hue='feature_variable', data=model_crash_data)\nplt.title(\"Box Plot for Roadway Junction Type and feature_variable\")\nplt.xticks(rotation=75)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we meticulously examine the dataset for missing values, distinguishing between numerical and categorical columns. Addressing missing data is crucial for ensuring the integrity and reliability of subsequent analyses. By systematically scrutinizing both numerical and categorical columns, we aim to identify any gaps in the dataset and determine the appropriate course of action. This meticulous approach allows us to maintain the quality of the data and make informed decisions regarding data imputation or removal.\n\n\nCode\n# Find numerical columns\nnumerical_cols = model_crash_data.select_dtypes(include = ['int64', 'float64'])\n\n# Calculate missing values count for each numerical column\nmissing_values_count = numerical_cols.isnull().sum()\n\n# Calculate missing rate for each numerical column\nmissing_rate = (missing_values_count / len(model_crash_data)) * 100\n\nmissing_data = pd.DataFrame({\n    'Missing Values': missing_values_count,\n    'Percentage (%)': missing_rate\n})\n\nprint('Analysis of Missing Values for numerical features: \\n\\n', missing_data, '\\n\\n')\n\n# Drop categorical columns with missing rate over 50%\ncolumns_to_drop = missing_rate[missing_rate &gt; 50].index\nmodel_crash_data = model_crash_data.drop(columns_to_drop, axis=1)\n\n# Find categorical columns\ncategorical_columns = model_crash_data.select_dtypes(include = ['object', 'category'])\n\n# Calculate missing values count for each categorical column\nmissing_values_count = categorical_columns.isnull().sum()\n\n# Calculate missing rate for each categorical column\nmissing_rate = (missing_values_count / len(crash_data)) * 100\n\nmissing_data = pd.DataFrame({\n    'Missing Values': missing_values_count,\n    'Percentage (%)': missing_rate\n})\n\nprint('Analysis of Missing Values for categorical features: \\n\\n', missing_data, '\\n\\n')\n\n# Drop categorical columns with missing rate over 50%\ncolumns_to_drop = missing_rate[missing_rate &gt; 50].index\ncrash_data = crash_data.drop(columns_to_drop, axis=1)\n\n\nAnalysis of Missing Values for numerical features: \n\n                   Missing Values  Percentage (%)\nfeature_variable               0        0.000000\nSpeed Limit                 1984        8.060781 \n\n\nAnalysis of Missing Values for categorical features: \n\n                              Missing Values  Percentage (%)\nLight Conditions                          0        0.000000\nManner of Collision                       3        0.012189\nRoad Surface Condition                    0        0.000000\nRoadway Junction Type                     3        0.012189\nTraffic Control Device Type               3        0.012189\nWeather Conditions                        0        0.000000\nAge                                       0        0.000000\nSex                                    1556        6.321862 \n\n\n\n\nGiven the critical nature of this analysis, handling missing values is a significant concern. The decision was made to remove rows with missing data rather than impute. This choice was driven by the observation that the column with the highest number of missing values had only 8% of its entries missing. By removing these rows, we avoid introducing bias that could arise from imputation, which is a particularly sensitive issue in crash modeling.\nRegarding data standardization and encoding, the “Speed Limit” variable was converted to a categorical data type. This decision reflects the fact that speed limits are often discrete and do not behave like continuous numerical variables. Treating them as categorical eliminates the risk of implying linear relationships or gradients where they do not exist.\nFor other categorical features, such as intersection type and weather conditions, one-hot encoding was employed. This approach was chosen over label encoding because it avoids the implication of ordinality among categorical variables. Label encoding could suggest an inherent order or ranking between categories, which is not appropriate for these types of features.\nBy using one-hot encoding, we retain the categorical nature of these features while preparing them for use in machine learning models. This step ensures that the encoded data accurately reflects the characteristics of the original dataset without introducing unintended biases.\n\n\nCode\n# Convert \"Speed Limit\" to a categorical data type\nmodel_crash_data_cleaned['Speed Limit'] = model_crash_data_cleaned['Speed Limit'].astype('category')\n\n# Select categorical columns\ncategorical_columns = model_crash_data_cleaned.select_dtypes(include=['object', 'category']).columns.tolist()\n\nprint(\"Categorical Columns:\")\nprint(categorical_columns)\nprint()\n\n# One-hot encode categorical variables\ncrash_data_encoded = pd.get_dummies(model_crash_data_cleaned, columns=categorical_columns, drop_first=True)\n\nprint(\"One-Hot Encoded Data:\")\ncrash_data_encoded.head()\n\n\nCategorical Columns:\n['Light Conditions', 'Manner of Collision', 'Road Surface Condition', 'Roadway Junction Type', 'Traffic Control Device Type', 'Weather Conditions', 'Speed Limit', 'Age', 'Sex']\n\nOne-Hot Encoded Data:\n\n\n\n\n\n\n\n\n\nfeature_variable\nLight Conditions_Dark - no lighting\nLight Conditions_Dark - unknown lighting\nLight Conditions_Dawn\nLight Conditions_Daylight\nLight Conditions_Dusk\nLight Conditions_Not reported\nLight Conditions_Other\nLight Conditions_Unknown\nManner of Collision_Front to Front\n...\nAge_25-34\nAge_35-44\nAge_45-54\nAge_55-64\nAge_65-74\nAge_75-84\nAge_&gt;84\nSex_M\nSex_U\nSex_X\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n5\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n\n\n5 rows × 88 columns\n\n\n\n\n\nShape of X_train: (17071, 87)\nShape of X_test: (4268, 87)\nShape of y_train: (17071,)\nShape of y_test: (4268,)\n\n\nFollowing the data preprocessing and encoding steps, the next phase involves defining and evaluating four distinct models: logistic regression, decision tree, random forest, and K-nearest neighbors (KNN). These models represent a range of approaches to classification, from linear methods to ensemble techniques and distance-based algorithms.\nTo assess the performance of these models, the dataset was split into training and testing sets using an 80/20 ratio, with 80% of the data used for training and 20% for testing. This split allows for robust evaluation of the models’ ability to generalize to new data.\nBelow, we report the results for each model using key metrics: accuracy, precision, recall, and F1 score. These metrics offer a comprehensive view of model performance, highlighting not only the overall accuracy but also the ability to correctly identify positive and negative cases (precision), the rate of true positive predictions (recall), and the balance between precision and recall (F1 score).\n\n\nCode\n# List of classifiers\nclassifiers = [log_reg, dtree, rf_classifier, knn]\n\n# Perform cross-validation and compute evaluation metrics for each classifier\nfor classifier in classifiers:\n    # Cross-validation\n    cv_scores = cross_val_score(classifier, X_train, y_train, cv=5)\n\n    # Compute evaluation metrics\n    accuracy = cv_scores.mean()\n    precision = precision_score(y_test, classifier.predict(X_test))\n    recall = recall_score(y_test, classifier.predict(X_test))\n    f1 = f1_score(y_test, classifier.predict(X_test))\n    \n    # Print the results\n    print('Classifier: ', str(classifier))\n    print('Accuracy: ', accuracy)\n    print('Precision: ', precision)\n    print('Recall: ', recall)\n    print('F1-Score: ', f1)\n    print()\n\n\nClassifier:  LogisticRegression(random_state=9)\nAccuracy:  0.7709567786077652\nPrecision:  0.43478260869565216\nRecall:  0.01936108422071636\nF1-Score:  0.03707136237256719\n\nClassifier:  DecisionTreeClassifier()\nAccuracy:  0.7529139594864314\nPrecision:  0.5145413870246085\nRecall:  0.4453049370764763\nF1-Score:  0.47742605085625317\n\nClassifier:  RandomForestClassifier()\nAccuracy:  0.782379591056034\nPrecision:  0.5930232558139535\nRecall:  0.345595353339787\nF1-Score:  0.4366972477064221\n\nClassifier:  KNeighborsClassifier()\nAccuracy:  0.7628725916281336\nPrecision:  0.5079646017699115\nRecall:  0.27783155856727976\nF1-Score:  0.3591989987484356\n\n\n\nTo evaluate the performance of our classifiers, we plotted the Receiver Operating Characteristic (ROC) curve and calculated the Area Under the Curve (AUC). The ROC curve helps us understand the trade-off between the True Positive Rate and the False Positive Rate, providing a visual representation of the model’s ability to distinguish between classes. A higher AUC value indicates a better-performing model, with a perfect classifier achieving an AUC of 1.\nIn the following plot, you will see ROC curves for K-Nearest Neighbors, Decision Tree, Random Forest, and Logistic Regression classifiers. Among these models, the Random Forest classifier had the highest AUC, indicating that it was the closest to the top-left corner of the ROC plot, demonstrating strong discriminative ability. This makes Random Forest the most promising model among those tested.\n\n\nCode\n# Plot ROC curves for different classifiers\nplt.figure(figsize=(8, 6))  # Set the plot size\n\n# ROC curve for KNN with AUC\nplt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_knn:.2f}) for KNN')\n\n# ROC curve for Decision Tree\nplt.plot(fpr_tree, tpr_tree, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc_tree:.2f}) for Decision Tree')\n\n# ROC curve for Random Forest\nplt.plot(fpr_forest, tpr_forest, color='red', lw=2, label=f'ROC curve (AUC = {roc_auc_forest:.2f}) for Random Forest')\n\n# ROC curve for Logistic Regression\nplt.plot(fpr_log, tpr_log, color='green', lw=2, label=f'ROC curve (AUC = {roc_auc_log:.2f}) for Logistic Regression')\n\n# Diagonal line representing random guessing\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Random classifier\n\n# Set plot limits and labels\nplt.xlim([0, 1])  # X-axis from 0 to 1 (False Positive Rate)\nplt.ylim([0, 1.05])  # Y-axis from 0 to slightly above 1 (True Positive Rate)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')  # Title\n\n# Display the legend in the lower right corner\nplt.legend(loc='lower right')\n\n# Show the plot\nplt.show() \n\n\n\n\n\n\n\n\n\nTo further examine model performance, we turn to confusion matrices, which provide a detailed breakdown of predictions versus actual outcomes. These matrices are particularly useful for identifying issues with class imbalance and evaluating model tendencies.\nThe confusion matrices presented below reveal a key insight: the models tend to predict 0 (non-severe crashes) far more frequently than 1 (severe crashes). This tendency is a common consequence of imbalanced data, where the majority class overwhelms the minority class. While this approach can yield high accuracy, it often comes at the expense of poor recall and precision, especially for the minority class.\nThese findings align with the earlier observation that our models, despite high accuracy, often fall short in terms of precision, recall, and F1 score. By examining these confusion matrices, we can better understand how model predictions are skewed and what adjustments might be needed to improve overall performance.\n\n\nCode\n# Create a 2x2 grid for the subplots\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))  # Define the grid structure\n\n# Confusion Matrix for Logistic Regression\ncm = confusion_matrix(y_test, predictions_log)\nsns.heatmap(cm, annot=True, fmt='g', ax=axs[0, 0])  # Plot in the top-left\naxs[0, 0].set_title('Logistic Regression Confusion Matrix',fontdict={\"size\":10})  # Set the title\n\n# Confusion Matrix for KNN\ncm = confusion_matrix(y_test, predictions_knn)\nsns.heatmap(cm, annot=True, fmt='g', ax=axs[0, 1])  # Plot in the top-right\naxs[0, 1].set_title('KNN Confusion Matrix',fontdict={\"size\":10})\n\n# Confusion Matrix for Decision Tree\ncm = confusion_matrix(y_test, predictions_tree)\nsns.heatmap(cm, annot=True, fmt='g', ax=axs[1, 0])  # Plot in the bottom-left\naxs[1, 0].set_title('Decision Tree Confusion Matrix',fontdict={\"size\":10})\n\n# Confusion Matrix for Random Forest\ncm = confusion_matrix(y_test, predictions_forest)\nsns.heatmap(cm, annot=True, fmt='g', ax=axs[1, 1])  # Plot in the bottom-right\naxs[1, 1].set_title('Random Forest Confusion Matrix',fontdict={\"size\":10})\n\n# Set common x and y labels\nfor ax in axs.flat:\n    ax.set_ylabel('Actual label')\n    ax.set_xlabel('Predicted label')\n\n# Adjust the layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot with all subplots\nplt.show()"
  },
  {
    "objectID": "index.html#discussion-of-results-conclusions",
    "href": "index.html#discussion-of-results-conclusions",
    "title": "ANALYTICAL AVENGERS",
    "section": "Discussion of Results & Conclusions",
    "text": "Discussion of Results & Conclusions\nThe objective of this project was to analyze the relationship between various features and a target variable to understand crash severity and evaluate the performance of different classifiers. After establishing a set of key feature variables, including ‘Speed Limit’, ‘Light Conditions’, ‘Weather Conditions’, ‘Road Surface Condition’, ‘Roadway Junction Type’, ‘Traffic Control Device Type’, ‘Manner of Collision’, ‘Age’, and ‘Sex’, we proceeded to build and test four machine learning models: Logistic Regression, Decision Tree, Random Forest, and K-Nearest Neighbors (KNN).\nWhile all models achieved an accuracy of approximately 78%, it became evident that accuracy alone wasn’t a sufficient measure due to the imbalanced nature of the dataset. This led us to examine additional metrics such as precision, recall, and F1 score, which offer more insights into model performance in the context of class imbalance. These metrics reveal that models tended to predict the majority class (non-severe crashes), yielding high accuracy but low recall and precision for the minority class (severe crashes).\nAmong the four classifiers, the Random Forest (RF) model demonstrated the best performance. It achieved a higher true positive rate, leading to improved recall, precision, and F1 score compared to other models. This result suggests that RF’s ensemble nature and ability to handle diverse data make it particularly effective for this type of analysis.\nDespite the promising results with Random Forest, there are several areas for future research and improvement. For instance, additional metrics, such as processing time and resource utilization, could be considered to evaluate model efficiency. Furthermore, addressing class imbalance through resampling techniques or class weights could enhance model accuracy and reliability for the minority class. Exploring different feature engineering approaches, integrating more contextual data, or experimenting with other machine learning algorithms may also yield improved outcomes.\nIn conclusion, this study highlights the challenges associated with imbalanced data and underscores the importance of considering multiple performance metrics beyond accuracy. Random Forest proved to be a strong candidate for predicting crash severity, but further research and refinement are needed to build more robust and efficient models. Future studies could focus on enhancing recall and precision for minority classes and exploring additional features that contribute to crash dynamics."
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "Our goal is to analyze how age correlates with dangerous crashes using a January 2024 crash dataset from Massachusetts, with the aim of developing a predictive model to understand and mitigate such incidents.\nInvestigating the relationship between age demographics and dangerous crashes holds significant importance in enhancing road safety measures and reducing the frequency of severe accidents. By delving into the January 2024 crash dataset from Massachusetts, our analysis seeks to uncover patterns and trends that can elucidate how age influences the likelihood and severity of crashes. Moreover, the development of predictive models based on this analysis offers practitioners and policymakers valuable tools for proactive decision-making and resource allocation. By accurately predicting areas and times with heightened crash risks based on age demographics, authorities can implement preemptive measures. Ultimately, our research endeavors not only contribute to the advancement of data-driven approaches in traffic safety but also hold the potential to make tangible improvements in road safety practices, benefiting both practitioners and society at large.\nHigh-Level Goals: Anomaly Detection in Road Safety: By identifying outliers in crash data—situations that deviate from the norm—we can pinpoint unusual patterns, such as unexpected high-risk areas for certain age groups or conditions, thereby enhancing targeted interventions. Association Rule Mining for Safety Measures: Through this technique, we aim to uncover hidden patterns and relationships between various factors (like weather conditions, time, and demographic details) contributing to severe crashes, facilitating the development of tailored preventive measures. Interactive Data Visualization: Developing an interactive dashboard that provides real-time insights into crash data, enabling policymakers, researchers, and the public to explore and understand the nuances of road safety dynamically."
  },
  {
    "objectID": "proposal.html#goal-and-motivation",
    "href": "proposal.html#goal-and-motivation",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "Our goal is to analyze how age correlates with dangerous crashes using a January 2024 crash dataset from Massachusetts, with the aim of developing a predictive model to understand and mitigate such incidents.\nInvestigating the relationship between age demographics and dangerous crashes holds significant importance in enhancing road safety measures and reducing the frequency of severe accidents. By delving into the January 2024 crash dataset from Massachusetts, our analysis seeks to uncover patterns and trends that can elucidate how age influences the likelihood and severity of crashes. Moreover, the development of predictive models based on this analysis offers practitioners and policymakers valuable tools for proactive decision-making and resource allocation. By accurately predicting areas and times with heightened crash risks based on age demographics, authorities can implement preemptive measures. Ultimately, our research endeavors not only contribute to the advancement of data-driven approaches in traffic safety but also hold the potential to make tangible improvements in road safety practices, benefiting both practitioners and society at large.\nHigh-Level Goals: Anomaly Detection in Road Safety: By identifying outliers in crash data—situations that deviate from the norm—we can pinpoint unusual patterns, such as unexpected high-risk areas for certain age groups or conditions, thereby enhancing targeted interventions. Association Rule Mining for Safety Measures: Through this technique, we aim to uncover hidden patterns and relationships between various factors (like weather conditions, time, and demographic details) contributing to severe crashes, facilitating the development of tailored preventive measures. Interactive Data Visualization: Developing an interactive dashboard that provides real-time insights into crash data, enabling policymakers, researchers, and the public to explore and understand the nuances of road safety dynamically."
  },
  {
    "objectID": "proposal.html#dataset",
    "href": "proposal.html#dataset",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "Dataset",
    "text": "Dataset\n\n# Read in the data\nurl = 'data/crash_data.csv'\ncrash_data = pd.read_csv(url)\n\n# # Display dimensions of the dataset\ndimensions = crash_data.shape\nprint(f\"Dimensions of the dataset: {dimensions} \\n\")\n\n# Display data types of each column\ndata_types = crash_data.dtypes\nprint(\"Display the data types for each feature:\")\nprint(data_types)\n\nnumerical_vars = crash_data.select_dtypes(include = ['int64', 'float64']).columns.tolist()\ncategorical_vars = crash_data.select_dtypes(include = ['object', 'category']).columns.tolist()\n\n# Display the counts of numerical and categorical variables\nprint(f\"\\nNumber of numerical variables: {len(numerical_vars)}\")\nprint(f\"Number of categorical variables: {len(categorical_vars)}\")\nprint('\\n')\n\ncrash_data.head()\n\nDimensions of the dataset: (25550, 72) \n\nDisplay the data types for each feature:\nCrash Number       object\nCity Town Name     object\nCrash Date         object\nCrash Severity     object\nCrash Status       object\n                   ...   \nVehicle Make       object\nVehicle Model      object\nPerson Number     float64\nAge               float64\nSex                object\nLength: 72, dtype: object\n\nNumber of numerical variables: 13\nNumber of categorical variables: 59\n\n\n\n\n\n\n\n\n\n\n\nCrash Number\nCity Town Name\nCrash Date\nCrash Severity\nCrash Status\nCrash Time\nCrash Year\nMax Injury Severity Reported\nNumber of Vehicles\nPolice Agency Type\n...\nX\nY\nLatitude\nLongitude\nVehicle Unit Number\nVehicle Make\nVehicle Model\nPerson Number\nAge\nSex\n\n\n\n\n0\n5342297\nLOWELL\n01/01/2024\nNon-fatal injury\nOpen\n3:26 AM\n2024.0\nPossible Injury (C)\n1.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n1.0\nHOND\nHR-V\n1.0\n32.0\nF - Female\n\n\n1\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n1.0\nNISS\nALTIMA\n1.0\n60.0\nM - Male\n\n\n2\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n2.0\nHOND\nACCORD\n2.0\nNaN\nNaN\n\n\n3\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n2.0\nHOND\nACCORD\n3.0\n31.0\nM - Male\n\n\n4\n5342292\nLOWELL\n01/01/2024\nProperty damage only (none injured)\nOpen\n12:48 AM\n2024.0\nNo Apparent Injury (O)\n2.0\nLocal police\n...\nNaN\nNaN\nNaN\nNaN\n2.0\nHOND\nACCORD\n4.0\nNaN\nM - Male\n\n\n\n\n5 rows × 72 columns"
  },
  {
    "objectID": "proposal.html#description-of-the-dataset",
    "href": "proposal.html#description-of-the-dataset",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "Description of the Dataset:",
    "text": "Description of the Dataset:\nThe dataset  Crash Query and Visualization that will be used for this project has been sourced from the official website of the Massachusetts Registry of Motor Vehicles. This dataset was chosen due to the relevance it holds in today’s day and age that is witness to an unfortunate increase in road accidents since the past 30 years. Analysing this data can help find patterns to create an algorithm or model that can predict crashes which could extensively assist in preventing accidents and possible deaths. By working on this data, we can contribute with identification of place/time of possible accidents that could aid in ensuring safer travel experiences for the public.\nThe dataset consists of 72 dimensions, some of which are - Crash Number, City Town/Name, Crash Date, Crash Severity, Crash Time, Crash Year, Max Injury Severity Reported, Age of Driver - Youngest Known, Age of Driver - Oldest Known etc.\nThe description of the variable can be found in README.md file."
  },
  {
    "objectID": "proposal.html#questions",
    "href": "proposal.html#questions",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1:\nWhich age groups are at the highest risk of getting into severe crashes, and how do factors like lighting, weather, road conditions, speed limits, and the number of vehicles involved contribute to the likelihood of certain age groups being in more danger?\n\n\nQuestion 2:\nIs it possible to develop a model that can accurately classify the severity of crashes based on our findings from the previous question about factors that contribute to said level of danger?"
  },
  {
    "objectID": "proposal.html#analysis-plan",
    "href": "proposal.html#analysis-plan",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "Analysis plan",
    "text": "Analysis plan\n\nAnalysis plan for Question 1\nUnderstanding who’s most likely to be in a serious crash is crucial for making our roads safer. We’ll be diving into crash data to see which age groups, for both drivers and pedestrians/cyclists, are most at risk for severe crashes (think bad injuries).\nNext, we’ll shift gears and investigate the role of the environment. We’ll see if crashes are more likely to be severe under certain conditions, like bad weather, nighttime driving, or busy roads. By pinpointing these risky situations, we can identify areas for improvement, like better lighting or stricter enforcement of speed limits.\nVariables for Question 1 : Age of Driver - Youngest Known Age of Driver - Oldest Known Age of Vulnerable User - Youngest Known Age of Vulnerable User - Oldest Known\nCrash Severity Variables: Crash Severity Max Injury Severity Reported\nOther Variables: Crash Date and Crash Time Number of Vehicles Light Conditions, Weather Conditions, Road Surface Conditions Speed Limit Vehicle Make, Vehicle Model\nVisualizations : we are going to used in this is Bar plots for Crash Severity by Age, Heatmaps for Combined Risk Factorsand for Speed and Severity we are going to use Scatter Plots\n\n\nAnalysis plan for Question 2\nTo predict the severity of crashes and classify them as dangerous or not, several machine learning (ML) methods can be effectively utilized. Each method brings its own strengths and weaknesses, and the choice often depends on the specific characteristics of the dataset, the complexity of the relationships between features, and the interpretability requirements. Logistic Regression, Decision Trees, Random Forests, and Support Vector Machines (SVMs) are the possible candidates for ML methods to implement.\nInitially, the dataset undergoes a preprocessing phase to handle missing values, encode categorical variables(all the categorical variables in our dataset), and potentially scale numerical features. The target variable, defining crash severity, is also established during this phase. The next step involves feature selection and engineering, where the most relevant features are identified to be used in model training using correlation analysis and random forest feature importance, and then the dimension reduction will be done using PCA analysis. Various ML models are then trained on a portion of the data, and their performance is evaluated using a separate test set. Metrics such as accuracy, precision, recall, and F1-score are commonly used to assess model performance. Based on these evaluations, the best-performing model is selected, tuned for optimal performance through hyperparameter optimization, and then validated to ensure its generalizability. Finally, the chosen model can be deployed to predict the severity of new crashes, providing valuable insights for safety measures and interventions."
  },
  {
    "objectID": "proposal.html#plan-of-attack",
    "href": "proposal.html#plan-of-attack",
    "title": "Prediction for Crash Severity for Enhanced Road Safety",
    "section": "Plan of Attack",
    "text": "Plan of Attack\n\n\n\n\n\n\n\n\n\n\n\nTask Name\nStatus\nAssignee\nDue\nPriority\nSummary\n\n\n\n\nDevelop Data Retrieval Code\nDone\nHM Abdul Fattah\n28-Mar-24\nHigh\nWriting a code to retrieve data, following best practices and considering error handling and data validation.\n\n\nComing Up with Questions and Choosing a Dataset\nDone\nGabriel Geffen\n28-Mar-24\nHigh\nCreating a structured framework for organizing the questions, considering logical flow, relevance, and coherence to real world applications.\n\n\nDescription of Dataset\nDone\nTanya George\n28-Mar-24\nHigh\nProviding an overview of the dataset to better understand which variables are relevant to the goal of our project.\n\n\nQuestion 1 Analysis\nDone\nDivya Dhole, Melika Akbarsharifi\n28-Mar-24\nHigh\nMelika Akbarsharifi wrote the variables that should be included for question 1 and Divaya Dhole wrote down the question Analysis\n\n\nQuestion 2 Analysis\nDone\nMohammad Ali Farmani\n28-Mar-24\nHigh\nMohammad Ali Farmani wrote down the question 2 analysis.\n\n\nPlan of Attack\nDone\nSunday Usman\n28-Mar-24\nHigh\nSunday wrote down the Plan of Attack in google sheet.\n\n\nImplementation of Solution for Question 1\nIn Progress\nTanya George, Divya Dhole, Melika Akbarsharifi\n14-Apr-24\nHigh\nAnalyzes crash data to identify age groups at highest risk, examining factors such as lighting, weather, and road conditions.\n\n\nModel setup and Implementation for Question 2\nNot started\nGabriel Geffen, HM Fattah, Mohammad Farmani, Sunday Usman\n28-Apr-24\nHigh\nFeature Engineering, Model Selection and Evaluation, Performance Assessment. Possibly, develop a dashboard for easy interpretation and communication of findings.\n\n\nReport writing\nNot started\nEveryone\n6-May-24\nHigh\nWriting a report and communicate all our findings. Everyone will work on seperate componet of the final report.\n\n\nPresentation\nNot started\nEveryone\n6-May-24\nHigh\nDelivering a presentation based on our discoveries. Everyone will contribute."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by ANALYTICAL AVENGERS For INFO 523 - Data Mining and Discovery at the University of Arizona, taught by Dr. Greg Chism. The team is comprised of the following team members.\n\nTanya Evita George- First year graduate student pursuing Data Science at the University of Arizona.\nMohammad Ali Farmani : 2nd year PhD student in Hydrology and Atmospheric Sciences in University of Arizona.\nMelika Akbarsharifi - second year Graduate - ECE major.\nSunday Usman - Graduate student - Systems and Industrial Engineering major.\nH M Abdul Fattah - Graduate student - Information Science, University of Arizona.\nDivya Liladhar Dhole - 1st year MS data science"
  },
  {
    "objectID": "presentation.html#correlation-and-patterns",
    "href": "presentation.html#correlation-and-patterns",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Correlation and Patterns",
    "text": "Correlation and Patterns\n\nCorrelation MatrixInsights\n\n\n\n\n\nCorrelation matrix and pair plot showing the relationship between numerical features and the target variable.\n\n\n\n\n\nThe correlation matrix helps identify the lack of strong linear relationships, suggesting that non-linear modeling techniques may be more effective."
  },
  {
    "objectID": "presentation.html#correlation-and-patterns-1",
    "href": "presentation.html#correlation-and-patterns-1",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Correlation and Patterns",
    "text": "Correlation and Patterns\n\nPair PlotInsights\n\n\n\n\n\npair plot provides for the distributions and relationships of numerical features.\n\n\n\n\n\nThe pair plot provides a visual insight into the distributions and relationships of numerical features, highlighting potential outliers and trends."
  },
  {
    "objectID": "presentation.html#test",
    "href": "presentation.html#test",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Test",
    "text": "Test\n\nROC CurveInsights\n\n\n\n\n\nROC Curve for different classifiers showing their performance in classifying crash severity.\n\n\n\n\n\nThe ROC curve illustrates the trade-off between sensitivity and specificity. Random Forest shows the highest AUC, indicating the best performance among the tested models in distinguishing between the crash severities."
  },
  {
    "objectID": "presentation.html#model-evaluation-metrics",
    "href": "presentation.html#model-evaluation-metrics",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Model Evaluation Metrics",
    "text": "Model Evaluation Metrics\n\nConfusion Matrices for ModelsInsights\n\n\n\n\n\nConfusion matrices for Logistic Regression, KNN, Decision Tree, and Random Forest models.\n\n\n\n\n\nThe confusion matrices provide insights into how well each model predicts the correct classes. While the Random Forest model shows the highest accuracy and precision, the Decision Tree model stands out in terms of recall and F1-score. It is notable that the Decision Tree model achieves the best balance between recall and precision among the classifiers, effectively managing class imbalance with the highest F1-score of 0.47."
  },
  {
    "objectID": "presentation.html#model-evaluation-metrics-1",
    "href": "presentation.html#model-evaluation-metrics-1",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Model Evaluation Metrics",
    "text": "Model Evaluation Metrics\n\n\n\nClassifier\nAccuracy\nPrecision\nRecall\nF1-Score\n\n\n\n\nLogistic Regression\n0.77\n0.43\n0.019\n0.03\n\n\nDecision Tree\n0.75\n0.51\n0.43\n0.47\n\n\nRandom Forest\n0.78\n0.59\n0.32\n0.42\n\n\nK Neighbors\n0.76\n0.50\n0.27\n0.35"
  },
  {
    "objectID": "presentation.html#model-evaluation-metrics-2",
    "href": "presentation.html#model-evaluation-metrics-2",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Model Evaluation Metrics",
    "text": "Model Evaluation Metrics\n\nROC CurveInsights\n\n\n\n\n\nROC Curve for different classifiers showing their performance in classifying crash severity.\n\n\n\n\n\nThe ROC curve illustrates the trade-off between sensitivity and specificity. Random Forest shows the highest AUC, indicating the best performance among the tested models in distinguishing between the crash severities."
  },
  {
    "objectID": "presentation.html#introduction-to-the-dataset",
    "href": "presentation.html#introduction-to-the-dataset",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "Introduction to the dataset",
    "text": "Introduction to the dataset\n\nThis dataset has been sourced from the official website of the Massachusetts Registry of Motor Vehicles.\nThe dataset is a compilation of car crash information from January 2024, Massachussets and it comprises of totally 72 dimensions.\nUsing important variables such as- Crash Number, Crash Severity, City/Town Name, Age of Driver etc. we analyze how different ages of driver can affect or play a factor in the severity of car crashes and accidents."
  },
  {
    "objectID": "presentation.html#section",
    "href": "presentation.html#section",
    "title": "Prediction of Crash Severity for Enhanced Road Safety",
    "section": "",
    "text": "Plot BInsights\n\n\n\n\n\nCrash Severity by Light Conditions:\n\n\n\n\n\nThe plot visualizes the distribution of crashes across different lighting conditions, categorized by crash severity .\nBy analyzing the height of the bars for each lighting condition and severity level, you can identify lighting conditions with a higher number of crashes of varying severity.\nthe plot might show that crashes with severe injuries are more frequent under dark conditions with no lighting compared to daylight conditions."
  }
]